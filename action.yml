name: 'Usable PR Validator'
description: 'Validate Pull Requests against your Usable knowledge base standards using ForgeCode with OpenRouter, OpenAI, Anthropic, or other LLM providers'
author: 'Flowcore'

branding:
  icon: 'check-circle'
  color: 'green'

inputs:
  prompt-file:
    description: 'Path to validation prompt markdown file (optional if use-dynamic-prompts is enabled)'
    required: false
    default: ''
  use-dynamic-prompts:
    description: 'Fetch latest prompt from Usable API instead of using static prompt file'
    required: false
    default: 'false'
  prompt-fragment-id:
    description: 'Usable fragment UUID to use as prompt (required when use-dynamic-prompts is true)'
    required: false
    default: ''
  merge-custom-prompt:
    description: 'Merge fetched Usable prompt with custom prompt-file (only when both are provided)'
    required: false
    default: 'true'
  override-comment:
    description: 'User comment requesting validation override or clarification (typically from @usable mention)'
    required: false
    default: ''
  provider:
    description: 'LLM provider: openrouter, openai, anthropic, or auto (auto-detect from env vars)'
    required: false
    default: 'auto'
  model:
    description: 'Model to use (e.g., anthropic/claude-haiku-4.5, anthropic/claude-3.7-sonnet, openai/gpt-4, meta-llama/llama-3.3-70b-instruct)'
    required: false
    default: 'anthropic/claude-haiku-4.5'
  api-key-secret:
    description: 'Name of secret containing API key (OPENROUTER_API_KEY, OPENAI_API_KEY, or ANTHROPIC_API_KEY)'
    required: false
    default: 'OPENROUTER_API_KEY'
  workspace-id:
    description: 'Usable workspace UUID (required - used to fetch MCP system prompt)'
    required: true
  fail-on-critical:
    description: 'Fail build when critical violations are found'
    required: false
    default: 'true'
  comment-mode:
    description: 'PR comment behavior: update, new, or none'
    required: false
    default: 'update'
  comment-title:
    description: 'Title for PR comment (used to identify which comment to update in multi-stage validations)'
    required: false
    default: 'Automated Standards Validation'
  artifact-retention-days:
    description: 'Days to retain validation report artifacts'
    required: false
    default: '30'
  max-retries:
    description: 'Maximum retry attempts for API failures'
    required: false
    default: '2'
  timeout-minutes:
    description: 'Maximum validation execution time in minutes'
    required: false
    default: '15'
  base-ref:
    description: 'Base reference for diff comparison (defaults to PR base branch). Useful for release-please branches to compare against last release tag.'
    required: false
    default: ''
  head-ref:
    description: 'Head reference for diff comparison (defaults to PR head branch)'
    required: false
    default: ''
  allow-web-fetch:
    description: 'Allow AI to use web_fetch tool for external resources (security consideration)'
    required: false
    default: 'false'

outputs:
  validation-status:
    description: 'Validation result: passed or failed'
    value: ${{ steps.validate.outputs.validation_status }}
  validation-passed:
    description: 'Boolean indicating if validation passed (true/false)'
    value: ${{ steps.validate.outputs.validation_passed }}
  critical-issues:
    description: 'Count of critical violations found'
    value: ${{ steps.validate.outputs.critical_issues }}
  report-artifact-name:
    description: 'Name of artifact containing validation report'
    value: ${{ steps.set-artifact-name.outputs.artifact_name }}

runs:
  using: 'composite'
  steps:
    - name: Validate inputs
      shell: bash
      run: |
        echo "::group::Validating inputs"
        
        # Check if workspace-id is provided
        if [ -z "${{ inputs.workspace-id }}" ]; then
          echo "::error::workspace-id is required"
          exit 1
        fi
        
        # Check if either prompt-file or use-dynamic-prompts is provided
        if [ -z "${{ inputs.prompt-file }}" ] && [ "${{ inputs.use-dynamic-prompts }}" != "true" ]; then
          echo "::error::Either prompt-file must be provided or use-dynamic-prompts must be enabled"
          exit 1
        fi
        
        # Check if prompt file exists (only if provided)
        if [ -n "${{ inputs.prompt-file }}" ] && [ ! -f "${{ inputs.prompt-file }}" ]; then
          echo "::error::Prompt file not found: ${{ inputs.prompt-file }}"
          exit 1
        fi
        
        # Validate comment mode
        if [[ ! "${{ inputs.comment-mode }}" =~ ^(update|new|none)$ ]]; then
          echo "::error::Invalid comment-mode. Must be: update, new, or none"
          exit 1
        fi
        
        # Validate boolean inputs
        if [[ ! "${{ inputs.use-dynamic-prompts }}" =~ ^(true|false)$ ]]; then
          echo "::error::Invalid use-dynamic-prompts. Must be: true or false"
          exit 1
        fi
        
        if [[ ! "${{ inputs.merge-custom-prompt }}" =~ ^(true|false)$ ]]; then
          echo "::error::Invalid merge-custom-prompt. Must be: true or false"
          exit 1
        fi
        
        if [[ ! "${{ inputs.allow-web-fetch }}" =~ ^(true|false)$ ]]; then
          echo "::error::Invalid allow-web-fetch. Must be: true or false"
          exit 1
        fi
        
        echo "✅ All inputs validated successfully"
        echo "::endgroup::"
    
    - name: Set Artifact Name
      id: set-artifact-name
      shell: bash
      run: |
        # Create a safe artifact name from the comment title
        TITLE="${{ inputs.comment-title }}"
        SAFE_NAME=$(echo "$TITLE" | tr '[:upper:]' '[:lower:]' | sed 's/[^a-z0-9]/-/g' | sed 's/--*/-/g' | sed 's/^-//' | sed 's/-$//')
        ARTIFACT_NAME="pr-validation-${SAFE_NAME}"
        echo "artifact_name=${ARTIFACT_NAME}" >> $GITHUB_OUTPUT
        echo "📦 Artifact name: ${ARTIFACT_NAME}"
    
    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '20'
    
    - name: Install ForgeCode CLI
      shell: bash
      run: |
        echo "::group::Installing ForgeCode CLI"
        npm install -g forgecode@latest
        echo "✅ ForgeCode CLI installed"
        echo "::endgroup::"
    
    - name: Setup Git
      shell: bash
      env:
        BASE_REF: ${{ inputs.base-ref }}
        HEAD_REF: ${{ inputs.head-ref }}
        DEFAULT_BASE: ${{ github.event.pull_request.base.ref }}
        DEFAULT_HEAD: ${{ github.event.pull_request.head.ref }}
        MAX_RETRIES: ${{ inputs.max-retries }}
      run: |
        echo "::group::Configuring Git"
        git config --global user.email "action@github.com"
        git config --global user.name "GitHub Action"
        
        # Function to fetch ref with retry logic
        fetch_ref_with_retry() {
          local ref="$1"
          local ref_type="$2"
          local retry_count=0
          local max_retries="${MAX_RETRIES:-2}"
          
          while [ $retry_count -le $max_retries ]; do
            echo "Attempt $((retry_count + 1))/$((max_retries + 1)): Fetching $ref_type ref: $ref"
            
            # Try to fetch as a branch first
            if git fetch origin "$ref:refs/remotes/origin/$ref" 2>/dev/null; then
              echo "✅ Successfully fetched $ref_type ref as branch: $ref"
              return 0
            fi
            
            # Try as a tag
            if git fetch --tags origin "refs/tags/$ref:refs/tags/$ref" 2>/dev/null; then
              echo "✅ Successfully fetched $ref_type ref as tag: $ref"
              return 0
            fi
            
            # Try fetching all refs (fallback)
            if git fetch origin "+refs/heads/$ref:refs/remotes/origin/$ref" 2>/dev/null; then
              echo "✅ Successfully fetched $ref_type ref using explicit refspec: $ref"
              return 0
            fi
            
            retry_count=$((retry_count + 1))
            if [ $retry_count -le $max_retries ]; then
              wait_time=$((2 ** retry_count))
              echo "⚠️ Failed to fetch $ref. Retrying after ${wait_time} seconds..."
              sleep $wait_time
            else
              echo "::warning::Failed to fetch $ref_type ref: $ref after $((max_retries + 1)) attempts"
              return 1
            fi
          done
        }
        
        # Determine which refs to fetch
        BASE_TO_FETCH="${BASE_REF:-$DEFAULT_BASE}"
        HEAD_TO_FETCH="${HEAD_REF:-$DEFAULT_HEAD}"
        
        # Fetch base ref
        if [ -n "$BASE_TO_FETCH" ]; then
          if ! fetch_ref_with_retry "$BASE_TO_FETCH" "base"; then
            echo "::error::Failed to fetch base ref: $BASE_TO_FETCH"
            echo "This may cause diff operations to fail."
          fi
        else
          echo "::warning::No base ref specified"
        fi
        
        # Fetch head ref
        if [ -n "$HEAD_TO_FETCH" ]; then
          if ! fetch_ref_with_retry "$HEAD_TO_FETCH" "head"; then
            echo "::error::Failed to fetch head ref: $HEAD_TO_FETCH"
            echo "This may cause diff operations to fail."
          fi
        else
          echo "::warning::No head ref specified"
        fi
        
        # Verify refs are available for diff
        echo ""
        echo "Verifying refs..."
        if [ -n "$BASE_TO_FETCH" ]; then
          if git rev-parse "origin/$BASE_TO_FETCH" >/dev/null 2>&1; then
            echo "✅ Base ref available: origin/$BASE_TO_FETCH"
          elif git rev-parse "$BASE_TO_FETCH" >/dev/null 2>&1; then
            echo "✅ Base ref available: $BASE_TO_FETCH"
          else
            echo "::warning::Base ref not found locally: $BASE_TO_FETCH"
          fi
        fi
        
        if [ -n "$HEAD_TO_FETCH" ]; then
          if git rev-parse "origin/$HEAD_TO_FETCH" >/dev/null 2>&1; then
            echo "✅ Head ref available: origin/$HEAD_TO_FETCH"
          elif git rev-parse "$HEAD_TO_FETCH" >/dev/null 2>&1; then
            echo "✅ Head ref available: $HEAD_TO_FETCH"
          else
            echo "::warning::Head ref not found locally: $HEAD_TO_FETCH"
          fi
        fi
        
        echo ""
        echo "✅ Git configured"
        echo "::endgroup::"
    
    - name: Setup LLM Provider Authentication
      shell: bash
      env:
        PROVIDER: ${{ inputs.provider }}
        API_KEY_SECRET: ${{ inputs.api-key-secret }}
      run: |
        ${{ github.action_path }}/scripts/setup-provider.sh
    
    - name: Setup MCP Server
      shell: bash
      env:
        USABLE_URL: ${{ env.USABLE_URL || 'https://usable.dev' }}
        USABLE_API_TOKEN: ${{ env.USABLE_API_TOKEN }}
        WORKSPACE_ID: ${{ inputs.workspace-id }}
      run: |
        ${{ github.action_path }}/scripts/setup-mcp.sh
    
    - name: Fetch Prompts from Usable
      shell: bash
      env:
        USE_DYNAMIC_PROMPTS: ${{ inputs.use-dynamic-prompts }}
        PROMPT_FRAGMENT_ID: ${{ inputs.prompt-fragment-id }}
        WORKSPACE_ID: ${{ inputs.workspace-id }}
        CUSTOM_PROMPT_FILE: ${{ inputs.prompt-file }}
        MERGE_CUSTOM_PROMPT: ${{ inputs.merge-custom-prompt }}
        USABLE_URL: ${{ env.USABLE_URL || 'https://usable.dev' }}
        USABLE_API_TOKEN: ${{ env.USABLE_API_TOKEN }}
        ACTION_PATH: ${{ github.action_path }}
      run: |
        ${{ github.action_path }}/scripts/fetch-prompt.sh
    
    - name: Run Validation
      id: validate
      shell: bash
      env:
        PROMPT_FILE: ${{ inputs.prompt-file }}
        USE_DYNAMIC_PROMPTS: ${{ inputs.use-dynamic-prompts }}
        PROVIDER: ${{ inputs.provider }}
        MODEL: ${{ inputs.model }}
        MAX_RETRIES: ${{ inputs.max-retries }}
        PR_NUMBER: ${{ github.event.pull_request.number }}
        PR_TITLE: ${{ github.event.pull_request.title }}
        PR_DESCRIPTION: ${{ github.event.pull_request.body }}
        PR_URL: ${{ github.event.pull_request.html_url }}
        PR_AUTHOR: ${{ github.event.pull_request.user.login }}
        PR_LABELS: ${{ join(github.event.pull_request.labels.*.name, ', ') }}
        BASE_BRANCH: ${{ inputs.base-ref || github.event.pull_request.base.ref }}
        HEAD_BRANCH: ${{ inputs.head-ref || github.event.pull_request.head.ref }}
        OVERRIDE_COMMENT: ${{ inputs.override-comment }}
        COMMENT_AUTHOR: ${{ env.COMMENT_AUTHOR }}
        ALLOW_WEB_FETCH: ${{ inputs.allow-web-fetch }}
        GIT_PAGER: cat
      run: |
        echo "::group::Running PR Validation"
        
        # Determine which prompt file to use
        if [ -f "/tmp/dynamic-prompt.md" ]; then
          ACTUAL_PROMPT="/tmp/dynamic-prompt.md"
          echo "Using dynamic prompt from fetch-prompt.sh"
        elif [ -n "$PROMPT_FILE" ] && [ -f "$PROMPT_FILE" ]; then
          ACTUAL_PROMPT="$PROMPT_FILE"
          echo "Using static prompt file: $PROMPT_FILE"
        else
          echo "::error::No valid prompt file found"
          exit 1
        fi
        
        # Configure ForgeCode model if specified
        if [ -n "$MODEL" ]; then
          echo "Configuring ForgeCode model: $MODEL"
          forge config set --model "$MODEL" || echo "Warning: Could not set model config"
        fi
        
        # Run ForgeCode directly with MCP stdio transport
        echo "🤖 Running ForgeCode CLI with MCP stdio transport"
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        echo "Provider: ${PROVIDER:-auto}"
        echo "Model: $MODEL"
        echo "Prompt: $ACTUAL_PROMPT"
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        
        # Run forge and capture output
        set +e
        forge -p "$(cat "$ACTUAL_PROMPT")" 2>&1 | tee /tmp/validation-full-output.md
        FORGE_EXIT=$?
        set -e
        
        echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
        
        if [ $FORGE_EXIT -ne 0 ]; then
          echo "::error::ForgeCode failed with exit code: $FORGE_EXIT"
          echo "validation_status=error" >> $GITHUB_OUTPUT
          echo "validation_passed=false" >> $GITHUB_OUTPUT
          echo "critical_issues=0" >> $GITHUB_OUTPUT
          exit 1
        fi
        
        # Process the JSON report if it exists
        if [ -f "/tmp/validation-report.json" ]; then
          # Construct markdown report
          ${{ github.action_path }}/scripts/construct-markdown.sh /tmp/validation-report.json /tmp/validation-report.md
          
          # Parse results
          STATUS=$(jq -r '.validationOutcome.status' /tmp/validation-report.json)
          CRITICAL=$(jq -r '.validationOutcome.criticalIssuesCount' /tmp/validation-report.json)
          
          if [ "$STATUS" = "PASS" ]; then
            echo "validation_status=passed" >> $GITHUB_OUTPUT
            echo "validation_passed=true" >> $GITHUB_OUTPUT
          else
            echo "validation_status=failed" >> $GITHUB_OUTPUT
            echo "validation_passed=false" >> $GITHUB_OUTPUT
          fi
          
          echo "critical_issues=${CRITICAL:-0}" >> $GITHUB_OUTPUT
          
          echo "✅ Validation completed: $STATUS (Critical: ${CRITICAL:-0})"
        else
          echo "::warning::No JSON report generated"
          cp /tmp/validation-full-output.md /tmp/validation-report.md || true
          echo "validation_status=completed" >> $GITHUB_OUTPUT
          echo "validation_passed=true" >> $GITHUB_OUTPUT
          echo "critical_issues=0" >> $GITHUB_OUTPUT
        fi
        
        echo "::endgroup::"
    
    - name: Post PR Comment
      if: inputs.comment-mode != 'none' && always()
      uses: actions/github-script@v7
      with:
        github-token: ${{ github.token }}
        script: |
          const fs = require('fs');
          const commentMode = '${{ inputs.comment-mode }}';
          const commentTitle = '${{ inputs.comment-title }}';
          const reportPath = '/tmp/validation-report.md';
          
          if (!fs.existsSync(reportPath)) {
            console.log('⚠️ No validation report found to post');
            return;
          }
          
          const report = fs.readFileSync(reportPath, 'utf8');
          // Create a unique marker based on the comment title
          const markerId = commentTitle.toLowerCase().replace(/[^a-z0-9]+/g, '-');
          const marker = `<!-- usable-pr-validator:${markerId} -->`;
          
          const commentBody = marker + '\n## 🤖 ' + commentTitle + '\n\n' +
            report + '\n\n---\n<details>\n<summary>📊 Validation Statistics</summary>\n\n' +
            '- **Provider**: ${{ inputs.provider }}\n' +
            '- **Model**: ${{ inputs.model }}\n' +
            '- **Standards Source**: ${{ inputs.mcp-server-url }}\n' +
            '- **Commit**: ' + context.payload.pull_request.head.sha.substring(0, 7) + '\n' +
            '- **Triggered by**: @' + context.actor + '\n\n' +
            '</details>';

          const { data: comments } = await github.rest.issues.listComments({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.payload.pull_request.number,
          });
          
          const existingComment = comments.find(comment => 
            comment.body.includes(marker)
          );
          
          if (commentMode === 'update' && existingComment) {
            await github.rest.issues.updateComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              comment_id: existingComment.id,
              body: commentBody,
            });
            console.log('✅ Updated existing PR comment');
          } else {
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.payload.pull_request.number,
              body: commentBody,
            });
            console.log('✅ Created new PR comment');
          }
    
    - name: Upload Validation Report
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: ${{ steps.set-artifact-name.outputs.artifact_name }}
        path: /tmp/validation-report.md
        retention-days: ${{ fromJSON(inputs.artifact-retention-days) }}
        if-no-files-found: warn
    
    - name: Upload Full Output
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: ${{ steps.set-artifact-name.outputs.artifact_name }}-full
        path: /tmp/validation-full-output.md
        retention-days: ${{ fromJSON(inputs.artifact-retention-days) }}
        if-no-files-found: warn
    
    - name: Cleanup Secrets
      if: always()
      shell: bash
      run: |
        # Remove temporary files containing sensitive data
        rm -f /tmp/forge-config.yaml
        rm -f /tmp/validation-*.md
        rm -f .mcp.json  # Remove MCP config with authentication token
        echo "✅ Temporary files cleaned up"
    
    - name: Fail on Critical Violations
      if: inputs.fail-on-critical == 'true' && steps.validate.outputs.validation_passed == 'false'
      shell: bash
      run: |
        echo "::error::❌ Critical violations found in PR validation"
        echo "Critical issues: ${{ steps.validate.outputs.critical_issues }}"
        exit 1
